{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling and Timing Code\n",
    "\n",
    "In the process of developing coe and creating data processing pipelines, there are often trade-offs you can make between various implementations.  Early in developing your algorithm, it can be counterproductive to worry about such things.  As Donald Knuth famously quipped, \"We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.\"\n",
    "\n",
    "But once ou have your code working it can be useful to dig into its efficiency a bit.  Sometimes it's useful to check the execution time of a given command or set of commands.  Other times it's useful to dig into a multiline porcess and determine where the bottleneck lies in some complicated series of operations.  IPython provies access to a wide array of functionality for this kind of timing and profiling of code.  Here we'll discuss the following IPython commands\n",
    "\n",
    "* `%time`\n",
    " * Time the execution of a single statement\n",
    "* `%timeit`\n",
    " * Time repeated execution of a single statement for more accuracy \n",
    "* `%prun`\n",
    " * Run code with the profiler\n",
    "* `%lprun`\n",
    " * Run code with the line-by-line profiler\n",
    "* `%memit`\n",
    " * Measure the memory use of a single statement\n",
    "* `%mprun`\n",
    " * Run code with the line-by-line memory profiler\n",
    " \n",
    "The last four commands are not bundled with IPython - You'll need to install the `line_profiler` and `memory_profiler` extentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.92 µs ± 250 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this operation is so fast, `%timeit` automatically does a large number of repetitions.  For slower commands, `%timeit` will automatically adjust and perform fewer repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06 s ± 18.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "total =  0\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        total += i * (-1) ** j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes repeating an operation is not the best option.  For example, if we have a list that we'dlike to sort, we might be misled by a prepeated operation.  Sorting a presorted list is much faster than sorting an unsorted list, so the repetition will skew the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.55 ms ± 162 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "L = [random.random() for i in range(100000)]\n",
    "%timeit L.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, the `%time` function may be a better choice.  It also is a good choice for longer-running commands, when short, system-related delays are unlikely to affect the result.  Let's time the sorting of an  unsorted and presorted list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting an unsorted list:\n",
      "Wall time: 33.6 ms\n"
     ]
    }
   ],
   "source": [
    "L = [random.random() for i in range(100000)]\n",
    "print(\"Sorting an unsorted list:\")\n",
    "%time L.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting an already sorted list: \n",
      "Wall time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Sorting an already sorted list: \")\n",
    "%time L.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `%timeit` is way quicker, even for a than a presorted list.  This is a result of the fact that `%timeit` does some clever things under the hood to prevent system calls from interfering with the timing.  For example, it prevents cleanup of unused Python objects (known as *garbage collection*) that might otherwise affect the timing results.  \n",
    "\n",
    "For `%time` as with `%timeit`, using double peprcent sign cell magic syntax allows timing of multiline scripts: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "total = 0\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        total += i*(-1)**j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on these functions as well as their available options, use the IPython help functionality (i.e., type `%time?`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling Full Scripts: `%prun`\n",
    "\n",
    "A program is mae of many single statements, and sometimes timeing these statements in context is more important than timing them on their own.  Python contains a built-in code profiler (which you can read about in the Python documentation), but IPython offers a much more convenient way to use this profilerm in the form of the magic function `%prun`\n",
    "\n",
    "By way of example, we'll define a simple function that does some calcuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_lists(N):\n",
    "    total = 0\n",
    "    for i in range(5):\n",
    "        L = [j ^ (j >> i) for j in range(N)]\n",
    "        total += sum(L)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call `%prun` with a function call to see the profiled results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%prun sum_of_lists(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a table that indicates, in order of total time on each function call, where the execution is spending the most time.  In this case, the bulk of execution time is in the list comprehension inside sum_of_lists.  From here, we could start thinking oabout what changes we might make to improve the performance in the algorithm.\n",
    "\n",
    "For more information on `%prun` type: `%prun?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line-by-Line Profiling with `%lprun`\n",
    "\n",
    "Needed to install `line_profiler` first\n",
    "\n",
    "This is the kind of like running `library()` in r, or like `import package`.  You need to do it in orer to run the magic command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `%lprun` command will do a line by line profiling of any function - in this case, we need to tell it explicitly wich functions we are interested in profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f sum_of_lists sum_of_lists(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time is reported in microseconds and we can see where the program is spending the most time.  At this point we may be able to use this info to modify aspects of the script and make it perfor better for our desired use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling Memory Use: `%memit` and `%mprun`\n",
    "\n",
    "Another aspect of profiling is the amout of memory an operation uses.  This ca nbe evaluated with another IPython extention, the `memory_profiler`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory profiler extension contains two useful magic functions: the `%memit` magic (which offers a memory-measuring equivalent of `%timeit`) and the `%mprun` fuction (which offers a memory-measuring equivalet of `%lprun`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 130.81 MiB, increment: 71.92 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit sum_of_lists(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a line-by-line description of memory use, we can use the `%mprun` magic.  Unfortunately this magic works only for functions defined in separate modules rather than the notebook itself, so we'll start by using the `%%file` magic to create a simple module called `mprun_demo.py` which contains our `sum_of_lists` function, with on addition that will make our memory profiling results more clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mprun_demo.py\n"
     ]
    }
   ],
   "source": [
    "%%file mprun_demo.py\n",
    "def sum_of_lists(N):\n",
    "    total = 0\n",
    "    for i in range(5):\n",
    "        L = [j ^ (j >> i) for j in range(N)]\n",
    "        total += sum(L)\n",
    "        del L # remove reference to L\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import the new version of this function and run the memory line profiler:\n",
    "\n",
    "This one takes a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from mprun_demo import sum_of_lists\n",
    "%mprun -f sum_of_lists sum_of_lists(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Increment column tells us how much each line affects the total memory budget: observe thtat when we create and delete the list L, we are adding about 25 MB of memory usage.  This is on top of the background memory usage from the Python interpreter itself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
